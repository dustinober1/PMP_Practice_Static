[
  {
    "id": "q-people-3-4-001",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "A developer who previously struggled with estimates now consistently delivers stories within the agreed time. What is the best way for the project manager to verify performance improvements?",
    "options": [
      {
        "id": "b",
        "label": "Review recent sprint data, confirm the improved predictability over several iterations, and discuss what changed in the developer's approach."
      },
      {
        "id": "a",
        "label": "Assume the improvement is permanent after one successful sprint and stop monitoring."
      },
      {
        "id": "c",
        "label": "Rely on the developer's self-assessment without looking at any data."
      },
      {
        "id": "d",
        "label": "Wait until the end of the project to see if the improvement remains."
      }
    ],
    "correctOptionId": "b",
    "explanation": "Option b is correct because verifying improvement requires objective data over time and understanding the factors that contributed to change. Option a is incorrect because a single sprint may not prove a stable trend. Option c is incorrect because self-assessment alone may not be sufficient. Option d is incorrect because waiting until project end delays feedback and adjustments.",
    "difficulty": "easy",
    "topics": [
      "trend analysis",
      "estimation improvement"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-002",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "After coaching, a tester is expected to reduce escaped defects. Three sprints later, the number of critical defects found in production has decreased. How should the project manager verify that the improvement is sustainable?",
    "options": [
      {
        "id": "b",
        "label": "Compare defect trends over several sprints, examine changes in test practices, and confirm that quality remains stable under similar conditions."
      },
      {
        "id": "a",
        "label": "Assume the coaching was successful based on one sprint's results and move on."
      },
      {
        "id": "c",
        "label": "Look at only one release and ignore other data points."
      },
      {
        "id": "d",
        "label": "Focus only on subjective opinions about quality and avoid using defect data."
      }
    ],
    "correctOptionId": "b",
    "explanation": "Option b is correct because sustainable improvement is shown through consistent data trends and confirmed changes in practices. Option a is incorrect because isolated success may be due to external factors. Option c is incorrect because one release is a limited sample. Option d is incorrect because ignoring objective quality indicators weakens verification.",
    "difficulty": "medium",
    "topics": [
      "defect trends",
      "quality metrics"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-003",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "A team member has been working on improving communication with stakeholders. Stakeholder surveys show higher satisfaction scores over the last quarter. What should the project manager do to verify this performance improvement?",
    "options": [
      {
        "id": "b",
        "label": "Review stakeholder feedback comments, discuss the change with the team member, and confirm that improved behaviors are consistently applied."
      },
      {
        "id": "a",
        "label": "Focus only on schedule metrics, since they are easier to measure."
      },
      {
        "id": "c",
        "label": "Assume improvement without verifying whether stakeholder expectations have changed."
      },
      {
        "id": "d",
        "label": "Rely solely on the team member's perception that communication is better."
      }
    ],
    "correctOptionId": "b",
    "explanation": "Option b is correct because verifying improvement combines data, qualitative feedback, and behavioral confirmation. Option a is incorrect because ignoring stakeholder satisfaction overlooks a key outcome. Option c is incorrect because context like changed expectations can affect scores. Option d is incorrect because perceptions alone may not match stakeholder views.",
    "difficulty": "medium",
    "topics": [
      "stakeholder surveys",
      "behavioral verification"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-004",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "An improvement initiative aimed to reduce handoff delays between analysis and development. Cycle time data shows faster transitions, but some team members say they feel rushed. How should the project manager verify the performance improvement?",
    "options": [
      {
        "id": "b",
        "label": "Examine cycle time metrics and gather qualitative feedback to ensure the faster handoffs do not compromise understanding or quality."
      },
      {
        "id": "a",
        "label": "Focus only on the cycle time reduction and declare success."
      },
      {
        "id": "c",
        "label": "Ignore metrics and base the conclusion only on whether people feel rushed."
      },
      {
        "id": "d",
        "label": "Abandon the improvement as soon as concerns are raised, without analysis."
      }
    ],
    "correctOptionId": "b",
    "explanation": "Option b is correct because verifying improvement means checking both quantitative gains and impacts on quality and workload. Option a is incorrect because faster handoffs may introduce other issues. Option c is incorrect because feelings alone do not provide the full picture. Option d is incorrect because stopping changes without analysis wastes potential benefits.",
    "difficulty": "hard",
    "topics": [
      "cycle time",
      "holistic verification"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-005",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "A coaching plan was created to help a junior team member present updates more clearly. Over several standups, their updates become concise and focused. What is the best way for the project manager to verify the improvement?",
    "options": [
      {
        "id": "b",
        "label": "Observe multiple standups, confirm the pattern of clear updates, and ask the team if they feel better informed."
      },
      {
        "id": "a",
        "label": "Base verification solely on the junior's feeling that they are more confident."
      },
      {
        "id": "c",
        "label": "Record a single standup and decide based only on that."
      },
      {
        "id": "d",
        "label": "Assume there is improvement without any observation because a plan was created."
      }
    ],
    "correctOptionId": "b",
    "explanation": "Option b is correct because direct observation over time and feedback from the audience help verify sustained improvement. Option a is incorrect because self-reported confidence may not reflect clarity. Option c is incorrect because one instance may not show consistency. Option d is incorrect because plans must be checked against results.",
    "difficulty": "easy",
    "topics": [
      "standup communication",
      "observation"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-006",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "The team implemented pair programming to reduce defects. Initial data shows fewer issues, but overtime hours have increased. How should the project manager verify whether the overall performance has improved?",
    "options": [
      {
        "id": "b",
        "label": "Review defect, throughput, and overtime data together and assess whether the benefits outweigh the costs."
      },
      {
        "id": "a",
        "label": "Evaluate only defect reduction and ignore overtime changes."
      },
      {
        "id": "c",
        "label": "Base verification solely on the team's subjective opinion of pair programming."
      },
      {
        "id": "d",
        "label": "Stop pair programming immediately once overtime is noticed, without further analysis."
      }
    ],
    "correctOptionId": "b",
    "explanation": "Option b is correct because verifying improvement requires a balanced view of quality, throughput, and sustainability. Option a is incorrect because ignoring overtime hides potential burnout risks. Option c is incorrect because perceptions should be combined with data. Option d is incorrect because abandoning the change without analysis wastes learning.",
    "difficulty": "hard",
    "topics": [
      "pair programming",
      "multi-metric evaluation"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-007",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "After conflict management training, there are fewer escalations to the project manager. What is the best way to verify that team conflict handling has truly improved?",
    "options": [
      {
        "id": "c",
        "label": "Ask team members how they are resolving disagreements, review escalation logs, and observe interactions during challenging discussions."
      },
      {
        "id": "b",
        "label": "Assume that fewer escalations mean conflicts no longer exist."
      },
      {
        "id": "a",
        "label": "Measure only the number of meetings per week and draw conclusions."
      },
      {
        "id": "d",
        "label": "Rely solely on the external trainer's opinion of the team's performance."
      }
    ],
    "correctOptionId": "c",
    "explanation": "Option c is correct because verifying improved conflict handling requires evidence that conflicts are being addressed constructively, not just hidden. Option b is incorrect because low escalations may mean avoidance. Option a is incorrect because meeting counts do not directly show conflict management quality. Option d is incorrect because external trainers may not see day-to-day behavior.",
    "difficulty": "medium",
    "topics": [
      "conflict resolution",
      "escalation logs"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-008",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "A data analyst used to deliver reports with many errors. After implementing checklists, error rates decline. How should the project manager verify that this improvement is reliable?",
    "options": [
      {
        "id": "c",
        "label": "Track error rates over multiple reporting cycles and confirm that the checklist is consistently used."
      },
      {
        "id": "b",
        "label": "Assume that one error-free report proves permanent improvement."
      },
      {
        "id": "a",
        "label": "Base verification solely on the analyst's statement that the checklist helps."
      },
      {
        "id": "d",
        "label": "Stop monitoring reports because the process has changed."
      }
    ],
    "correctOptionId": "c",
    "explanation": "Option c is correct because repeated measurement and process adherence verification show whether improvement is stable. Option b is incorrect because a single success is not sufficient. Option a is incorrect because perception alone is incomplete. Option d is incorrect because oversight remains necessary while new practices are adopted.",
    "difficulty": "easy",
    "topics": [
      "checklists",
      "error tracking"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-009",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "The team adopted a new retrospective format to improve follow-through on actions. After two months, some actions are still not completed. How should the project manager verify whether performance has improved?",
    "options": [
      {
        "id": "c",
        "label": "Review the backlog of retrospective actions, completion rates, and their impact on metrics, then adjust the format if needed."
      },
      {
        "id": "b",
        "label": "Assume the new format works because meetings feel more energetic."
      },
      {
        "id": "a",
        "label": "Measure only the length of retrospectives and decide improvement based on shorter duration."
      },
      {
        "id": "d",
        "label": "Stop capturing actions because they are not all completed."
      }
    ],
    "correctOptionId": "c",
    "explanation": "Option c is correct because verifying improvement means checking whether actions are completed and affecting outcomes, not just whether meetings feel different. Option b is incorrect because perceived energy may not equate to results. Option a is incorrect because shorter meetings alone do not show performance gains. Option d is incorrect because abandoning actions removes a lever for change.",
    "difficulty": "medium",
    "topics": [
      "retrospective actions",
      "completion rate"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-010",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "A support engineer was often late responding to incidents. After clarifying expectations, their response times improved. What should the project manager do to verify this improvement?",
    "options": [
      {
        "id": "c",
        "label": "Analyze incident response logs over a defined period and confirm that the improved response times meet agreed targets."
      },
      {
        "id": "b",
        "label": "Trust verbal assurances without looking at incident data."
      },
      {
        "id": "a",
        "label": "Review only one week of incident data and consider that enough."
      },
      {
        "id": "d",
        "label": "Focus only on the volume of incidents and ignore response times."
      }
    ],
    "correctOptionId": "c",
    "explanation": "Option c is correct because verifying improved responsiveness requires objective measurement against targets. Option b is incorrect because assurances without data may be incomplete. Option a is incorrect because one week may not represent long-term behavior. Option d is incorrect because frequency and timeliness both matter.",
    "difficulty": "easy",
    "topics": [
      "incident response",
      "service levels"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-011",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "A mentoring program pairs senior and junior team members to improve skills. How should the project manager verify whether this program is improving performance?",
    "options": [
      {
        "id": "c",
        "label": "Collect feedback from mentors and mentees, review junior performance metrics over time, and look for increased independence."
      },
      {
        "id": "b",
        "label": "Assume mentoring is effective because participants meet regularly."
      },
      {
        "id": "a",
        "label": "Base verification only on the total number of mentoring sessions completed."
      },
      {
        "id": "d",
        "label": "Ask mentors to report only positive stories so the program appears successful."
      }
    ],
    "correctOptionId": "c",
    "explanation": "Option c is correct because combining feedback with observable performance changes shows whether mentoring is effective. Option b is incorrect because frequency alone does not prove impact. Option a is incorrect because count of sessions is a limited indicator. Option d is incorrect because selective reporting hides issues.",
    "difficulty": "medium",
    "topics": [
      "mentoring outcomes",
      "independence"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-012",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "To improve predictability, the team agreed to limit work in progress (WIP). After implementation, throughput appears more stable. How should the project manager verify that performance improvements are attributable to the WIP limit?",
    "options": [
      {
        "id": "c",
        "label": "Compare throughput and cycle time before and after WIP limits while checking for other changes that might affect results."
      },
      {
        "id": "b",
        "label": "Credit WIP limits for any positive change without examining other factors."
      },
      {
        "id": "a",
        "label": "Focus only on team satisfaction scores and ignore delivery metrics."
      },
      {
        "id": "d",
        "label": "Assume the improvement is temporary and make no effort to verify it."
      }
    ],
    "correctOptionId": "c",
    "explanation": "Option c is correct because assessing causality requires comparing metrics and understanding context. Option b is incorrect because multiple factors can influence performance. Option a is incorrect because delivery outcomes are part of verification. Option d is incorrect because giving up on verification misses a chance to learn.",
    "difficulty": "hard",
    "topics": [
      "WIP limits",
      "causal analysis"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-013",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "The team had issues with unclear acceptance criteria. After implementing a definition of ready, fewer stories are blocked. What should the project manager do to verify the improvement?",
    "options": [
      {
        "id": "d",
        "label": "Track the number of blocked stories and clarification requests over time and confirm that the definition of ready is being used consistently."
      },
      {
        "id": "b",
        "label": "Assume improvement because the team discussed the definition once."
      },
      {
        "id": "c",
        "label": "Measure only the number of stories completed, regardless of quality."
      },
      {
        "id": "a",
        "label": "Rely solely on the product owner's opinion of whether things feel smoother."
      }
    ],
    "correctOptionId": "d",
    "explanation": "Option d is correct because verifying the effect of new criteria involves checking both practice adoption and related metrics. Option b is incorrect because talking about changes does not guarantee results. Option c is incorrect because completion alone may hide rework. Option a is incorrect because one person's perception is incomplete.",
    "difficulty": "medium",
    "topics": [
      "definition of ready",
      "blocked work"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-014",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "A chronically late team member was coached on time management. Their attendance improved for several weeks but then slipped again. How should the project manager verify performance improvement in this case?",
    "options": [
      {
        "id": "d",
        "label": "Examine attendance patterns over a longer period, talk with the team member about obstacles, and adjust the plan if needed."
      },
      {
        "id": "b",
        "label": "Consider the initial improvement sufficient evidence and ignore the relapse."
      },
      {
        "id": "c",
        "label": "Focus only on their task completion and disregard attendance."
      },
      {
        "id": "a",
        "label": "Immediately escalate to HR without reviewing data or speaking with the person."
      }
    ],
    "correctOptionId": "d",
    "explanation": "Option d is correct because verifying improvement includes detecting regression and understanding reasons behind it. Option b is incorrect because ignoring relapse misses a chance to refine support. Option c is incorrect because attendance affects collaboration. Option a is incorrect because escalation without analysis can be premature.",
    "difficulty": "hard",
    "topics": [
      "regression",
      "attendance patterns"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-015",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "After introducing automated tests, build failures are detected earlier. What should the project manager do to verify that this improvement is contributing to better overall performance?",
    "options": [
      {
        "id": "d",
        "label": "Monitor build failure frequency, time to fix, and production incident trends to see if earlier detection is reducing downstream issues."
      },
      {
        "id": "b",
        "label": "Measure only how many tests were written, without linking to outcomes."
      },
      {
        "id": "c",
        "label": "Assume that adding tests always improves performance and skip measurement."
      },
      {
        "id": "a",
        "label": "Stop using automated tests once the first few builds pass successfully."
      }
    ],
    "correctOptionId": "d",
    "explanation": "Option d is correct because the value of automation is verified through its impact on defects and response time, not just test counts. Option b is incorrect because volume alone does not show effectiveness. Option c is incorrect because assumptions without data can be misleading. Option a is incorrect because discontinuing tests wastes investment.",
    "difficulty": "medium",
    "topics": [
      "automated testing",
      "downstream impact"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-016",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "To reduce context switching, the team introduced focus blocks with no meetings. After a trial period, some members report deeper work, while others feel disconnected. How should the project manager verify overall performance improvements?",
    "options": [
      {
        "id": "d",
        "label": "Compare throughput, quality, and satisfaction data before and after the change and adjust the approach based on findings."
      },
      {
        "id": "b",
        "label": "Base the decision solely on the views of those who like focus blocks."
      },
      {
        "id": "c",
        "label": "Judge success only on the number of meetings removed from the calendar."
      },
      {
        "id": "a",
        "label": "Assume focus blocks help everyone equally and keep them unchanged."
      }
    ],
    "correctOptionId": "d",
    "explanation": "Option d is correct because verifying improvement includes multiple metrics and perspectives, informing adjustments. Option b is incorrect because it ignores those negatively affected. Option c is incorrect because fewer meetings alone may not mean better performance. Option a is incorrect because assuming uniform benefit overlooks diversity in work styles.",
    "difficulty": "hard",
    "topics": [
      "focus time",
      "multi-perspective evaluation"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-017",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "A new checklist for release readiness was adopted to prevent last-minute surprises. The first two releases after adoption went smoothly. What is the best way to verify that the checklist is effective?",
    "options": [
      {
        "id": "d",
        "label": "Track release issues over several cycles, ensure the checklist is followed, and confirm that identified risks are being mitigated."
      },
      {
        "id": "b",
        "label": "Assume the checklist is effective after the first smooth release."
      },
      {
        "id": "c",
        "label": "Use the checklist only when there is time available before release."
      },
      {
        "id": "a",
        "label": "Stop updating the checklist even if new types of issues appear."
      }
    ],
    "correctOptionId": "d",
    "explanation": "Option d is correct because confirming effectiveness requires tracking results and adherence over multiple releases and updating based on experience. Option b is incorrect because one release does not prove robustness. Option c is incorrect because inconsistent use undermines verification. Option a is incorrect because static checklists may become outdated.",
    "difficulty": "medium",
    "topics": [
      "release readiness",
      "continuous improvement"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-018",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "Team members used to work in silos, but after cross-training sessions, more people can cover each other's tasks. How should the project manager verify this improvement in flexibility?",
    "options": [
      {
        "id": "d",
        "label": "Review how often team members successfully cover for others, monitor handover issues, and ask about confidence in cross-functional work."
      },
      {
        "id": "b",
        "label": "Count the number of cross-training sessions only, regardless of outcomes."
      },
      {
        "id": "c",
        "label": "Assume flexibility improved because cross-training was offered, without checking usage."
      },
      {
        "id": "a",
        "label": "Base verification solely on a single instance when someone covered another role."
      }
    ],
    "correctOptionId": "d",
    "explanation": "Option d is correct because actual use of cross-functional skills and reduced bottlenecks show real flexibility improvements. Option b is incorrect because session count alone does not show application. Option c is incorrect because offering training does not guarantee adoption. Option a is incorrect because one example does not capture ongoing performance.",
    "difficulty": "medium",
    "topics": [
      "cross-training",
      "flexibility"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-019",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "Previously, changes were often implemented without documentation. After a documentation policy, the number of undocumented changes drops. What should the project manager do to verify that performance has genuinely improved?",
    "options": [
      {
        "id": "a",
        "label": "Audit a sample of recent changes to confirm documentation quality and completeness, and check for related incidents."
      },
      {
        "id": "b",
        "label": "Rely solely on the number of documents created, without checking their content."
      },
      {
        "id": "c",
        "label": "Assume compliance once the policy is communicated and stop monitoring."
      },
      {
        "id": "d",
        "label": "Focus only on reducing the time spent on documentation, not its accuracy."
      }
    ],
    "correctOptionId": "a",
    "explanation": "Option a is correct because confirming improvement includes reviewing the quality of documentation and its effect on stability. Option b is incorrect because quantity alone can be misleading. Option c is incorrect because policies require verification. Option d is incorrect because documentation speed without accuracy undermines value.",
    "difficulty": "hard",
    "topics": [
      "documentation quality",
      "compliance audit"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-020",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "The project manager introduced a daily 15-minute planning huddle to improve coordination. After a month, some metrics improved slightly. What should the project manager do next to verify whether to keep this practice?",
    "options": [
      {
        "id": "a",
        "label": "Compare coordination-related issues, rework, and team feedback from before and after the huddles and decide based on overall impact."
      },
      {
        "id": "b",
        "label": "Keep the huddles indefinitely without evaluation because they are already in place."
      },
      {
        "id": "c",
        "label": "Discontinue huddles after one month regardless of results to recover time."
      },
      {
        "id": "d",
        "label": "Base the decision only on whether the project manager personally likes the meetings."
      }
    ],
    "correctOptionId": "a",
    "explanation": "Option a is correct because decisions about new practices should be based on multiple indicators and team input. Option b is incorrect because unexamined practices may waste time. Option c is incorrect because ending useful huddles prematurely may harm coordination. Option d is incorrect because personal preference is not a sufficient criterion.",
    "difficulty": "medium",
    "topics": [
      "coordination practices",
      "practice evaluation"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-021",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "The team introduced a new risk review routine. Initially, risks are identified earlier and mitigations are assigned. How should the project manager verify that this improvement is impacting project performance?",
    "options": [
      {
        "id": "a",
        "label": "Track the number of realized risks, their impact, and how often mitigations reduce issues compared to previous periods."
      },
      {
        "id": "b",
        "label": "Measure only the number of risks logged, assuming more risks logged is always better."
      },
      {
        "id": "c",
        "label": "Base verification solely on the length of risk review meetings."
      },
      {
        "id": "d",
        "label": "Assume risk reviews help and stop tracking risk outcomes."
      }
    ],
    "correctOptionId": "a",
    "explanation": "Option a is correct because improvement in risk management should be reflected in fewer or less severe realized risks. Option b is incorrect because risk count alone may reflect awareness, not performance. Option c is incorrect because meeting length does not show effectiveness. Option d is incorrect because unmonitored risks may still harm the project.",
    "difficulty": "hard",
    "topics": [
      "risk reviews",
      "risk outcomes"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-022",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "A performance improvement plan aimed to increase collaboration between developers and operations. After changes, deployment frequency increases and rollback events decrease. What is the best way to verify this improvement?",
    "options": [
      {
        "id": "a",
        "label": "Analyze deployment metrics over time and confirm collaboration practices, such as joint planning and shared dashboards, are in place."
      },
      {
        "id": "b",
        "label": "Look only at the number of deployments without considering rollback rates."
      },
      {
        "id": "c",
        "label": "Base verification solely on a single stakeholder's impression of team collaboration."
      },
      {
        "id": "d",
        "label": "Stop monitoring deployment performance once frequency has increased."
      }
    ],
    "correctOptionId": "a",
    "explanation": "Option a is correct because verifying collaboration improvements means checking both process adoption and outcomes like deployment performance. Option b is incorrect because higher frequency without stability can be risky. Option c is incorrect because one opinion is insufficient. Option d is incorrect because ongoing monitoring is needed.",
    "difficulty": "medium",
    "topics": [
      "DevOps collaboration",
      "deployment metrics"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-023",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "Previously, retrospectives resulted in long lists of actions that rarely got done. After limiting actions to a few high-impact items, completion rates improved. How should the project manager verify performance improvements from this change?",
    "options": [
      {
        "id": "a",
        "label": "Track the completion rate and impact of selected actions over several iterations to confirm process effectiveness."
      },
      {
        "id": "b",
        "label": "Assume improvement because the action list is shorter."
      },
      {
        "id": "c",
        "label": "Evaluate only whether meetings finish faster, not whether actions are done."
      },
      {
        "id": "d",
        "label": "Stop documenting actions entirely and rely on memory."
      }
    ],
    "correctOptionId": "a",
    "explanation": "Option a is correct because improvement is demonstrated when a manageable number of actions get completed and drive positive change. Option b is incorrect because shorter lists alone do not guarantee outcomes. Option c is incorrect because duration is less important than follow-through. Option d is incorrect because relying on memory reduces accountability.",
    "difficulty": "medium",
    "topics": [
      "retrospective focus",
      "action impact"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-024",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "A time tracking analysis revealed frequent multitasking. After limiting concurrent tasks, team members report feeling more focused. What should the project manager do to verify that performance has improved?",
    "options": [
      {
        "id": "a",
        "label": "Review throughput, quality, and lead time data before and after the change to confirm measurable benefits."
      },
      {
        "id": "b",
        "label": "Rely only on individual feelings of focus without checking outcomes."
      },
      {
        "id": "c",
        "label": "Measure only the number of tasks in the backlog and ignore flow metrics."
      },
      {
        "id": "d",
        "label": "Assume multitasking is always harmful and keep the new rule without validation."
      }
    ],
    "correctOptionId": "a",
    "explanation": "Option a is correct because both experience and metrics are needed to verify improved performance. Option b is incorrect because perceived focus may not translate into results. Option c is incorrect because backlog size alone is incomplete. Option d is incorrect because practices should still be validated in context.",
    "difficulty": "hard",
    "topics": [
      "multitasking",
      "flow metrics"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  },
  {
    "id": "q-people-3-4-025",
    "domainId": "people",
    "taskId": "people-3",
    "enablerIds": [
      "e-people-3-4"
    ],
    "text": "At the end of an improvement cycle, the project manager wants to report on performance improvements to the sponsor. What is the most appropriate way to verify improvements before reporting?",
    "options": [
      {
        "id": "a",
        "label": "Correlate changes in key metrics with implemented actions, validate findings with the team, and highlight both results and remaining risks."
      },
      {
        "id": "b",
        "label": "Select only the most favorable data and omit anything that suggests limited improvement."
      },
      {
        "id": "c",
        "label": "Base the report solely on a few anecdotal success stories."
      },
      {
        "id": "d",
        "label": "Report that improvements occurred because an action plan was created, without checking impact."
      }
    ],
    "correctOptionId": "a",
    "explanation": "Option a is correct because sponsors need evidence-based, balanced reporting that links actions to outcomes. Option b is incorrect because cherry-picking data reduces credibility. Option c is incorrect because anecdotes alone are insufficient. Option d is incorrect because plans without impact do not demonstrate improvement.",
    "difficulty": "medium",
    "topics": [
      "sponsor reporting",
      "evidence-based improvement"
    ],
    "process": "plan-stakeholder-engagement",
    "knowledgeAreaId": "stakeholder"
  }
]
